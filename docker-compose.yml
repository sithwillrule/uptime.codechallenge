version: '3.8'

services:
  # ClickHouse Database
  clickhouse:
    image: clickhouse/clickhouse-server:24.1.5.6-alpine
    container_name: clickhouse
    ports:
      - "8123:8123"
      - "9004:9000"
      - "9009:9009"
    volumes:
      - clickhouse_data:/var/lib/clickhouse
      - clickhouse_logs:/var/log/clickhouse-server
    environment:
      CLICKHOUSE_DB: default
      CLICKHOUSE_USER: default
      CLICKHOUSE_DEFAULT_ACCESS_MANAGEMENT: 1
      CLICKHOUSE_PASSWORD: clickhouse123
    ulimits:
      nofile:
        soft: 262144
        hard: 262144
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:8123/ping"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - data-network

  # Kafka in KRaft mode (Raft-based)
  kafka:
    image: confluentinc/cp-kafka:7.6.0
    container_name: kafka
    ports:
      - "9092:9092"
      - "9093:9093"
      - "9101:9101"
    environment:
      # KRaft settings
      KAFKA_NODE_ID: 1
      KAFKA_PROCESS_ROLES: 'broker,controller'
      KAFKA_CONTROLLER_QUORUM_VOTERS: '1@kafka:29093'
      
      # Listeners
      KAFKA_LISTENERS: 'PLAINTEXT://kafka:29092,CONTROLLER://kafka:29093,PLAINTEXT_HOST://0.0.0.0:9092'
      KAFKA_ADVERTISED_LISTENERS: 'PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092'
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: 'CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT'
      KAFKA_CONTROLLER_LISTENER_NAMES: 'CONTROLLER'
      KAFKA_INTER_BROKER_LISTENER_NAME: 'PLAINTEXT'
      
      # KRaft Configuration
      CLUSTER_ID: 'MkU3OEVBNTcwNTJENDM2Qk'
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_JMX_PORT: 9101
      KAFKA_JMX_HOSTNAME: localhost
      
      # Log settings
      KAFKA_LOG_DIRS: '/var/lib/kafka/data'
      KAFKA_NUM_PARTITIONS: 1
      KAFKA_DEFAULT_REPLICATION_FACTOR: 1
      KAFKA_MIN_INSYNC_REPLICAS: 1
      KAFKA_LOG_RETENTION_HOURS: 168
      KAFKA_LOG_SEGMENT_BYTES: 1073741824
      KAFKA_LOG_RETENTION_CHECK_INTERVAL_MS: 300000
      
      # Performance settings
      KAFKA_COMPRESSION_TYPE: 'gzip'
      KAFKA_CONFLUENT_SUPPORT_METRICS_ENABLE: false
    volumes:
      - kafka_data:/var/lib/kafka/data
    command: >
      bash -c "
        # Format storage if needed
        if [ ! -f /var/lib/kafka/data/meta.properties ]; then
          echo 'Formatting Kafka storage...'
          /bin/kafka-storage format -t $${CLUSTER_ID} -c /etc/kafka/kafka.properties --ignore-formatted
        fi
        # Start Kafka
        /etc/confluent/docker/run
      "
    healthcheck:
      test: ["CMD-SHELL", "kafka-broker-api-versions --bootstrap-server kafka:29092 | grep -q ApiVersion"]
      interval: 30s
      timeout: 10s
      retries: 10
      start_period: 60s
    networks:
      - data-network


networks:
  data-network:
    driver: bridge

volumes:
  clickhouse_data:
    driver: local
  clickhouse_logs:
    driver: local
  kafka_data:
    driver: local
